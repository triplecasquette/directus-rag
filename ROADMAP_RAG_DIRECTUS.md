# ðŸ“š RAG Directus â€” Complete Technical Roadmap

## ðŸŽ¯ Project Objective

Develop a RAG (Retrieval-Augmented Generation) system that is **local, open source, and integrated with the Directus documentation**.  
The MVP should allow users to ask a question in natural language and receive a contextual answer based on the `.md` files from the official documentation hosted on GitHub.

Target audience: English-speaking â†’ international  
LLM model: local via Ollama (e.g., Dolphin)  
Embedding: local via `bge-m3`  
Vector store: Qdrant (self-hostable)

## ðŸ“¦ Chosen Tech Stack

| Component             | Validated Choice            | Reason                                                                 |
|-----------------------|-----------------------------|------------------------------------------------------------------------|
| Frontend              | Nuxt (latest)               | Easy integration into Directus docs (also in Nuxt)                     |
| Chunking              | Custom TypeScript           | Logical split based on Markdown (`##`, paragraphs, soft overlap)       |
| Embedding             | `bge-m3` (Ollama)           | Local, fast, suitable for English, 1024-dim, sufficient for MVP        |
| Vector store          | Qdrant                      | Simple API, open source, cloud/on-prem compatible,
better than Postgres + pgvector for this use case |
| LLM                   | Dolphin (Ollama)            | Local model, reasonable performance, can understand French             |
| Architecture          | Lightweight DDD / SOLID     | Allows swapping any component without rewriting everything             |
| Chunk format          | Markdown `.md`              | Files extracted from Directus GitHub docs                              |
| Build mode            | TypeScript ESM + `ts-node/esm` | Fully typed, explicit `.ts` imports, scripts in `scripts/`          |

## âœ… Completed Steps

### 1. ðŸ”§ Initial Setup
- Nuxt project started
- Strict `.ts` files with ESM (`allowImportingTsExtensions`)
- DDD structure `rag/` set up (`chunking/`, `embedding/`, `domain/`â€¦)

### 2. ðŸ§± Chunking
- Splitting `.md` files by `##` (sections)
- Auto re-split into paragraphs if too large (> 500 tokens)
- Textual overlap option implemented but disabled for V1
- Cleanly typed `DocumentChunk`
- Tested via `scripts/test-chunk.ts`

### 3. ðŸ”¢ Local Embedding
- `NomicEmbedder` class implementing `Embedder`
- Calls `http://localhost:11434/api/embeddings`
- Works with Ollama
- Vector format: `number[]` of size 768
- Tested with `scripts/test-embed.ts`

## ðŸ”œ Next Steps

### 4. ðŸ§  Qdrant Vector Store

#### File to create: `rag/vector/QdrantVectorStore.ts`

#### Methods to implement:
- `addDocuments(chunks: DocumentChunk[]): Promise<void>`
- `search(query: string): Promise<SearchResult[]>`

#### Constraints:
- Use Qdrant REST API (`http://localhost:6333`)
- Index based on generated `embeddings`
- Each document must store `metadata` (source, heading, etc.)

### 5. ðŸ“¦ Full Corpus Indexing

#### Script to create: `scripts/index-all-docs.ts`

Tasks:
- Read all `.md` files in `data/`
- Chunk each file
- Embed each chunk
- Index via `QdrantVectorStore`

### 6. ðŸ’¬ Minimalist RAG Interface

Component: `ChatRAG.vue` in `Nuxt`

Function:
- User input (question)
- `embed()` the question
- `search()` in Qdrant
- Concatenate chunks into prompt
- Send to an LLM (Dolphin)
- Display the answer

Bonus: 
- Add `source` in the answer (links, titles) â†’ V2

## ðŸ§  Strategic Decisions

- **Target language:** English only for V1
- **Multilingual:** planned for V2 (via translation or parallel embeddings)
- **No cloud dependency** â†’ fully local or self-hostable
- **No sub-chunking by tokens** â†’ paragraphs are enough for Directus docs
- **Planned extensibility** â†’ all components are abstracted via interfaces

## ðŸ’¡ Business Architecture

```ts
// Example abstraction interface
export interface Embedder {
  embed(text: string): Promise<number[]>
}

export interface VectorStore {
  addDocuments(docs: DocumentChunk[]): Promise<void>
  search(query: string): Promise<SearchResult[]>
}
```

## ðŸ“‚ Current Structure

```
/rag-directus
/rag-directus
â”œâ”€â”€ components
â”‚   â”œâ”€â”€ atoms/
â”‚   â”œâ”€â”€ molecules/
â”‚   â”œâ”€â”€ organisms/
â”‚   â””â”€â”€ svg/
â”œâ”€â”€ data
â”‚   â””â”€â”€ directus-docs/
â”œâ”€â”€ layouts
â”‚   â””â”€â”€ default.vue
â”œâ”€â”€ pages
â”‚   â””â”€â”€ index.vue
â”œâ”€â”€ public
â”‚   â”œâ”€â”€ favicon.ico
â”‚   â”œâ”€â”€ robots.txt
â”‚   â””â”€â”€ fonts/
â”œâ”€â”€ server
â”‚   â””â”€â”€ api
â”‚       â””â”€â”€ rag/
â”‚           â”œâ”€â”€ ask.post.ts
â”‚           â””â”€â”€ callRagPipeline.ts
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â”œâ”€â”€ chunking/
â”‚   â”‚   â”œâ”€â”€ embedding/
â”‚   â”‚   â”œâ”€â”€ generation/
â”‚   â”‚   â”œâ”€â”€ indexer/
â”‚   â”‚   â”œâ”€â”€ rerank/
â”‚   â”‚   â””â”€â”€ vector-store/
â”‚   â”œâ”€â”€ schemas/
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ clear-qdrant.ts
â”‚   â”‚   â””â”€â”€ tests/
â”‚   â”‚       â”œâ”€â”€ 01-chunking.test.ts
â”‚   â”‚       â”œâ”€â”€ 02-embedding.test.ts
â”‚   â”‚       â”œâ”€â”€ 03-qdrant.test.ts
â”‚   â”‚       â”œâ”€â”€ 04-index.test.ts
â”‚   â”‚       â”œâ”€â”€ 05-search.test.ts
â”‚   â”‚       â””â”€â”€ 06-generation.test.ts
â”‚   â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ stores/
â”‚   â”œâ”€â”€ types/
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ .editorconfig
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ app.vue
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ eslint.config.mjs
â”œâ”€â”€ nuxt.config.ts
â”œâ”€â”€ package.json
â”œâ”€â”€ pnpm-lock.yaml
â”œâ”€â”€ pnpm-workspace.yaml
â”œâ”€â”€ prettier.config.cjs
â”œâ”€â”€ README.md
â”œâ”€â”€ ROADMAP_RAG_DIRECTUS.md
â””â”€â”€ tsconfig.json
```

## ðŸ§ª Tests

All business components are testable in isolation:
- `01-chunking.test.ts` â†’ checks splitting
- `02-embedding.test.ts` â†’ checks embedding call to Ollama
- `03-qdrant.test.ts` â†’ checks Qdrant vector store integration
- `04-index.test.ts` â†’ checks full indexing pipeline
- `05-search.test.ts` â†’ checks search functionality
- `06-generation.test.ts` â†’ checks LLM generation pipeline

## ðŸ MVP Objective

1. The user asks a question
2. The system checks if the question is about Directus (LLM filter)
3. If relevant, the question is embedded into a vector
4. The vector is compared to documentation chunks (semantic search)
5. (Planned) Chunks are reranked for better relevance
6. The most relevant chunks are formatted into a prompt
7. The prompt is sent to the LLM, which generates an answer

## ðŸ” Post-MVP Ideas

- Multilingual (langchain-style)
- Enriched format (links to sources, metadata) -> first steps already here
- Dockerization
- Native integration into `directus/docs`
