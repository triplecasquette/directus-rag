# The backend for vector storage, currently using Qdrant (a local vector database compatible with SQLite-like storage)
VECTOR_BACKEND=qdrant

# The name of the collection used to store document chunks in the vector database
VECTOR_COLLECTION_NAME=docs_chunks

# URL to the Qdrant instance, where vector operations (add, search, etc.) are performed
VECTORSTORE_URL=http://localhost:6333

# URL to the Ollama instance for embedding generation using the specified model
OLLAMA_URL=http://localhost:11434/api/generate

# The model used for generating embeddings via Ollama; currently set to 'bge-m3'
OLLAMA_EMBED_MODEL=bge-m3

# The primary model used for generating responses in the RAG system; currently using 'dolphin3'
RAG_LLM_GENERATION_MODEL=dolphin3

# The model used as a safeguard to verify or validate generated responses; currently set to the latest version of 'llama3'
RAG_LLM_SAFEGUARD_MODEL=llama3:latest

# The model used to re-rank potential responses for relevance or accuracy; currently using 'dolphin3'
RAG_LLM_RERANK_MODEL=dolphin3

# The number of top-k chunks to retrieve during vector search before generating a response
RAG_TOP_K=5
